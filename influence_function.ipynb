{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import influence\n",
    "from mnist_convnet import deepnn\n",
    "from utils import corrupt_mnist\n",
    "import copy\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "# Import data\n",
    "mnist = corrupt_mnist(input_data.read_data_sets(\"mnist_data\", one_hot=True), 0.03)\n",
    "\n",
    "# Create the model\n",
    "with tf.name_scope(\"net\"):\n",
    "    input_ph = tf.placeholder(tf.float32, [None, 784])\n",
    "    y, weights = deepnn(input_ph)\n",
    "\n",
    "# Define loss and optimizer\n",
    "with tf.name_scope(\"loss\"):\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10], name=\"y_target\")\n",
    "    batch_loss = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)\n",
    "    regularization = tf.reduce_sum( [tf.nn.l2_loss(w) for w in weights])\n",
    "    cross_entropy = tf.reduce_sum(batch_loss) + regularization * 0.001\n",
    "\n",
    "lr = tf.Variable(0.1)\n",
    "opt = tf.train.AdamOptimizer(lr)\n",
    "grads_and_vars = opt.compute_gradients(cross_entropy)\n",
    "train_step = opt.apply_gradients(grads_and_vars)\n",
    "\n",
    "# Test trained model\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "gs = [g for g,v in grads_and_vars if g is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saver.restore(sess, \"/home/cgel/deep_quad/mnist_convnet_corrupted.ckpt\")\n",
    "\n",
    "summary_writter = tf.summary.FileWriter(\"./Hvp_summaries\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_feed_dic = {input_ph: mnist.test.images, y_: mnist.test.labels}\n",
    "\n",
    "batch_xs, batch_ys = mnist.train.next_batch(mnist.test.images.shape[0])\n",
    "train_feed_dic = {input_ph:batch_xs, y_:batch_ys}\n",
    "\n",
    "testset = (mnist.test.images, mnist.test.labels)\n",
    "trainset = (mnist.train.images, mnist.train.labels)\n",
    "#trainset = (mnist.train.images[0:10000], mnist.train.labels[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 0.11355\n",
      "- iter: 0\n",
      "Error: 0.162412480722\n",
      "dad: 0.000178858786579\n",
      "alpha: 72.0938086232\n",
      "beta: 2.04564644968\n",
      "Ad scaling: 0.0242070441411\n",
      "- iter: 1\n",
      "Error: 0.112668858627\n",
      "dad: 0.000848822907774\n",
      "alpha: 31.0757582494\n",
      "beta: 0.481247986026\n",
      "Ad scaling: 0.0224415272928\n",
      "- iter: 2\n",
      "Error: 0.0951080621811\n",
      "dad: 0.000281123951726\n",
      "alpha: 45.1554216454\n",
      "beta: 0.712569245963\n",
      "Ad scaling: 0.0184562325042\n",
      "- iter: 3\n",
      "Error: 0.0672559756662\n",
      "dad: 0.000220587374809\n",
      "alpha: 41.0066388405\n",
      "beta: 0.500065257628\n",
      "Ad scaling: 0.0179880184422\n",
      "- iter: 4\n",
      "Error: 0.0599372183621\n",
      "dad: 0.000113202056796\n",
      "alpha: 39.9583172315\n",
      "beta: 0.794203332819\n",
      "Ad scaling: 0.0217350714731\n",
      "- iter: 5\n",
      "Error: 0.0395181733315\n",
      "dad: 0.000155126896407\n",
      "alpha: 23.1582698209\n",
      "beta: 0.434711025004\n",
      "Ad scaling: 0.0304292269451\n",
      "- iter: 6\n",
      "Error: 0.0301927786964\n",
      "dad: 4.48930097367e-05\n",
      "alpha: 34.7868532922\n",
      "beta: 0.583730404486\n",
      "Ad scaling: 0.0240857999965\n",
      "- iter: 7\n",
      "Error: 0.017551961602\n",
      "dad: 2.88606135299e-05\n",
      "alpha: 31.5864358464\n",
      "beta: 0.337944331296\n",
      "Ad scaling: 0.0240584741422\n",
      "- iter: 8\n",
      "Error: 0.0114299700155\n",
      "dad: 5.83813929829e-06\n",
      "alpha: 52.7687608415\n",
      "beta: 0.424071472038\n",
      "Ad scaling: 0.0169362320985\n",
      "- iter: 9\n",
      "Error: 0.00808992391637\n",
      "dad: 2.37056443718e-06\n",
      "alpha: 55.1110444543\n",
      "beta: 0.500954062416\n",
      "Ad scaling: 0.0167752678701\n"
     ]
    }
   ],
   "source": [
    "scale = float(len(trainset[0]))\n",
    "inf = influence.Influence(cross_entropy/scale, input_ph, y_, testset, trainset, cg_iters = 30, dampening=0.001, vervose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inf.recompute_s(cg_iters = 20, dampening=4e-2, vervose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "influences_corrupted = []\n",
    "influences_non_corrupted = []\n",
    "grads_corrupted = []\n",
    "grads_non_corrupted = []\n",
    "#size = len(mnist.train.labels)\n",
    "size = 1000\n",
    "for i in range(size):\n",
    "    z = (mnist.train.images[i:i+1], mnist.train.labels[i:i+1])\n",
    "    influ, z_grad = inf.of_and_g(z)\n",
    "    if mnist.train.corrupted_mask[i]:\n",
    "        influences_corrupted.append(influ)\n",
    "        grads_corrupted.append(z_grad)\n",
    "    else:\n",
    "        influences_non_corrupted.append(influ)\n",
    "        grads_non_corrupted.append(z_grad)\n",
    "all_influences = influences_corrupted + influences_non_corrupted\n",
    "all_grads = grads_corrupted + grads_non_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non corrupted\n",
      "mean -6.47728385977e-08\n",
      "std 1.21111189844e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"non corrupted\")\n",
    "print(\"mean\",np.mean( influences_non_corrupted))\n",
    "print(\"std\",np.std( influences_non_corrupted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrupted\n",
      "mean -1.88751401152e-06\n",
      "std 5.31467498935e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"corrupted\")\n",
    "print(\"mean\",np.mean( influences_corrupted))\n",
    "print(\"std\",np.std( influences_corrupted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inf.s = influence.lset(inf.s, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def train(n, mnist=mnist, learning_rate=0.1e-4):\n",
    "#    sess.run(tf.assign(lr, learning_rate))\n",
    "#    for _ in range(n):\n",
    "#        batch_xs, batch_ys = mnist.train.next_batch(64)\n",
    "#        sess.run(train_step, feed_dict={input_ph: batch_xs, y_: batch_ys})\n",
    "        \n",
    "def test():\n",
    "    test_acc, test_loss = sess.run([accuracy, cross_entropy], feed_dict={input_ph: mnist.test.images,\n",
    "                                  y_: mnist.test.labels})\n",
    "    train_acc, train_loss = sess.run([accuracy, cross_entropy], feed_dict=train_feed_dic)\n",
    "    print(\"test acc\", test_acc)\n",
    "    print(\"test loss\", test_loss)\n",
    "    print(\"train acc\", train_acc)\n",
    "    print(\"train loss\", train_loss) \n",
    "    print(\"---\")\n",
    "    \n",
    "def testset_loss():\n",
    "    return sess.run(cross_entropy, feed_dict={input_ph: mnist.test.images, y_: mnist.test.labels})\n",
    "\n",
    "def train(n, trainset, learning_rate=0.1e-4):\n",
    "    sess.run(tf.assign(lr, learning_rate))\n",
    "    for _ in range(n):\n",
    "        batch_xs, batch_ys = trainset.next_batch(500)\n",
    "        sess.run(train_step, feed_dict={input_ph: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return a new dataset \n",
    "def mnist_i(i):\n",
    "    new_mnist = copy.deepcopy(mnist)\n",
    "    new_len = new_mnist.train.images.shape[0] -1\n",
    "    new_images_shape = [new_len] + list(new_mnist.train.images.shape[1:])\n",
    "    new_labels_shape = [new_len] + list(new_mnist.train.labels.shape[1:])\n",
    "    new_mnist.train.images.resize(new_images_shape)\n",
    "    new_mnist.train.labels.resize(new_labels_shape)\n",
    "    new_mnist.train.images[:] = np.delete(mnist.train.images, i, axis=0)\n",
    "    new_mnist.train.labels[:] = np.delete(mnist.train.labels, i, axis=0)\n",
    "    return new_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return a new dataset \n",
    "def mnist_i2(i):\n",
    "    return (np.delete(mnist.train.images, i, axis=0), np.delete(mnist.train.labels, i, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data):\n",
    "        self.images = data[0]\n",
    "        self.labels = data[1]\n",
    "        self.a = 0 \n",
    "        self.b = None \n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        if self.b == None or self.b == len(self.labels):\n",
    "            self.a = 0\n",
    "            self.b = batch_size\n",
    "        else:\n",
    "            self.a = self.b\n",
    "            self.b = min(self.a + batch_size, len(self.labels) )\n",
    "            \n",
    "        return (self.images[self.a:self.b], self.labels[self.a:self.b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'inf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f8ad9d224403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mz_influ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mof_and_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mgrads_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_grad\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnew_mnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_i2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inf' is not defined"
     ]
    }
   ],
   "source": [
    "# leave one out retraining \n",
    "subset = np.arange(0,1000)\n",
    "influence_acc = []\n",
    "grads_l = []\n",
    "saver.restore(sess, \"/home/cgel/deep_quad/mnist_convnet_corrupted.ckpt\")\n",
    "base_testset_loss = testset_loss()\n",
    "for i in subset:\n",
    "    print(i)\n",
    "    z = (mnist.train.images[i:i+1], mnist.train.labels[i:i+1])\n",
    "    z_influ, z_grad = inf.of_and_g(z)\n",
    "    grads_l.append(z_grad*scale)\n",
    "    new_mnist = Dataset(mnist_i2(i))\n",
    "    print(new_mnist.labels.shape)\n",
    "    train(30000, new_mnist, learning_rate=1e-7)\n",
    "    d_loss = base_testset_loss - testset_loss()\n",
    "    influence_acc.append( (z_influ * scale, d_loss) )\n",
    "    saver.restore(sess, \"/home/cgel/deep_quad/mnist_convnet_corrupted.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "influence d_loss\n",
      "0.00117045197073 -1.25342\n"
     ]
    }
   ],
   "source": [
    "infs = []\n",
    "d_losses = []\n",
    "print(\"influence\", \"d_loss\")\n",
    "for pair in influence_acc:\n",
    "    infs.append(pair[0])\n",
    "    d_losses.append(pair[1])\n",
    "    print(pair[0], pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.239258\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, \"/home/cgel/deep_quad/mnist_convnet_corrupted.ckpt\")\n",
    "base_testset_loss = testset_loss()\n",
    "train(1000, mnist.train, learning_rate=1e-7)\n",
    "d_loss = base_testset_loss - testset_loss()\n",
    "print(d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver.restore(sess, \"/home/cgel/deep_quad/mnist_convnet_corrupted.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc 0.0846\n",
      "test loss 30870.3\n",
      "train acc 0.0891\n",
      "train loss 31078.4\n",
      "---\n",
      "test acc 0.9632\n",
      "test loss 1621.01\n",
      "train acc 0.9499\n",
      "train loss 2671.71\n",
      "---\n",
      "test acc 0.9712\n",
      "test loss 1323.3\n",
      "train acc 0.9639\n",
      "train loss 1933.37\n",
      "---\n",
      "test acc 0.9732\n",
      "test loss 1229.11\n",
      "train acc 0.9698\n",
      "train loss 1451.83\n",
      "---\n",
      "test acc 0.9725\n",
      "test loss 1166.37\n",
      "train acc 0.9756\n",
      "train loss 1049.5\n",
      "---\n",
      "test acc 0.9734\n",
      "test loss 1083.27\n",
      "train acc 0.9822\n",
      "train loss 731.857\n",
      "---\n",
      "test acc 0.9726\n",
      "test loss 1060.42\n",
      "train acc 0.9905\n",
      "train loss 486.994\n",
      "---\n",
      "test acc 0.9716\n",
      "test loss 1048.83\n",
      "train acc 0.9961\n",
      "train loss 306.672\n",
      "---\n",
      "test acc 0.9711\n",
      "test loss 1017.23\n",
      "train acc 0.9983\n",
      "train loss 184.784\n",
      "---\n",
      "test acc 0.9701\n",
      "test loss 1028.05\n",
      "train acc 0.9988\n",
      "train loss 113.906\n",
      "---\n",
      "test acc 0.9704\n",
      "test loss 1045.9\n",
      "train acc 0.9994\n",
      "train loss 69.462\n",
      "---\n",
      "XXXX\n",
      "test acc 0.9698\n",
      "test loss 1084.29\n",
      "train acc 0.9999\n",
      "train loss 42.4314\n",
      "---\n",
      "test acc 0.9689\n",
      "test loss 1126.6\n",
      "train acc 0.9999\n",
      "train loss 32.3282\n",
      "---\n",
      "test acc 0.9689\n",
      "test loss 1157.06\n",
      "train acc 1.0\n",
      "train loss 19.7326\n",
      "---\n",
      "test acc 0.9695\n",
      "test loss 1188.89\n",
      "train acc 1.0\n",
      "train loss 14.7018\n",
      "---\n",
      "test acc 0.9667\n",
      "test loss 1287.82\n",
      "train acc 0.9994\n",
      "train loss 40.3506\n",
      "---\n",
      "test acc 0.9697\n",
      "test loss 1238.43\n",
      "train acc 1.0\n",
      "train loss 10.3981\n",
      "---\n",
      "test acc 0.9693\n",
      "test loss 1251.98\n",
      "train acc 1.0\n",
      "train loss 9.45525\n",
      "---\n",
      "test acc 0.9683\n",
      "test loss 1322.95\n",
      "train acc 1.0\n",
      "train loss 10.986\n",
      "---\n",
      "test acc 0.9697\n",
      "test loss 1281.04\n",
      "train acc 1.0\n",
      "train loss 7.83585\n",
      "---\n",
      "test acc 0.9698\n",
      "test loss 1284.01\n",
      "train acc 1.0\n",
      "train loss 7.35903\n",
      "---\n",
      "test acc 0.9694\n",
      "test loss 1299.8\n",
      "train acc 1.0\n",
      "train loss 7.18464\n",
      "---\n",
      "test acc 0.9695\n",
      "test loss 1306.42\n",
      "train acc 1.0\n",
      "train loss 6.74382\n",
      "---\n",
      "test acc 0.9689\n",
      "test loss 1314.59\n",
      "train acc 1.0\n",
      "train loss 6.47041\n",
      "---\n",
      "test acc 0.9691\n",
      "test loss 1313.23\n",
      "train acc 1.0\n",
      "train loss 6.18862\n",
      "---\n",
      "test acc 0.9697\n",
      "test loss 1303.65\n",
      "train acc 1.0\n",
      "train loss 5.90618\n",
      "---\n",
      "XXXX\n",
      "test acc 0.9694\n",
      "test loss 1295.51\n",
      "train acc 1.0\n",
      "train loss 5.67874\n",
      "---\n",
      "test acc 0.9694\n",
      "test loss 1295.59\n",
      "train acc 1.0\n",
      "train loss 5.58141\n",
      "---\n",
      "test acc 0.9692\n",
      "test loss 1291.66\n",
      "train acc 1.0\n",
      "train loss 5.55953\n",
      "---\n",
      "test acc 0.9694\n",
      "test loss 1291.77\n",
      "train acc 1.0\n",
      "train loss 5.52102\n",
      "---\n",
      "test acc 0.9691\n",
      "test loss 1290.52\n",
      "train acc 1.0\n",
      "train loss 5.46961\n",
      "---\n",
      "test acc 0.9692\n",
      "test loss 1282.54\n",
      "train acc 1.0\n",
      "train loss 5.41735\n",
      "---\n",
      "test acc 0.9691\n",
      "test loss 1282.88\n",
      "train acc 1.0\n",
      "train loss 5.39521\n",
      "---\n",
      "test acc 0.9693\n",
      "test loss 1279.39\n",
      "train acc 1.0\n",
      "train loss 5.34093\n",
      "---\n",
      "test acc 0.9689\n",
      "test loss 1285.67\n",
      "train acc 1.0\n",
      "train loss 5.34137\n",
      "---\n",
      "test acc 0.9689\n",
      "test loss 1281.23\n",
      "train acc 1.0\n",
      "train loss 5.2611\n",
      "---\n",
      "XXXX\n",
      "test acc 0.9691\n",
      "test loss 1280.37\n",
      "train acc 1.0\n",
      "train loss 5.22092\n",
      "---\n",
      "test acc 0.9692\n",
      "test loss 1278.35\n",
      "train acc 1.0\n",
      "train loss 5.22632\n",
      "---\n",
      "test acc 0.9693\n",
      "test loss 1278.46\n",
      "train acc 1.0\n",
      "train loss 5.21676\n",
      "---\n",
      "test acc 0.9692\n",
      "test loss 1277.41\n",
      "train acc 1.0\n",
      "train loss 5.21618\n",
      "---\n",
      "test acc 0.9694\n",
      "test loss 1277.23\n",
      "train acc 1.0\n",
      "train loss 5.21483\n",
      "---\n",
      "test acc 0.9693\n",
      "test loss 1278.12\n",
      "train acc 1.0\n",
      "train loss 5.20718\n",
      "---\n",
      "test acc 0.9693\n",
      "test loss 1277.95\n",
      "train acc 1.0\n",
      "train loss 5.19952\n",
      "---\n",
      "test acc 0.9693\n",
      "test loss 1277.82\n",
      "train acc 1.0\n",
      "train loss 5.20765\n",
      "---\n",
      "test acc 0.9692\n",
      "test loss 1277.34\n",
      "train acc 1.0\n",
      "train loss 5.19207\n",
      "---\n",
      "test acc 0.9695\n",
      "test loss 1277.04\n",
      "train acc 1.0\n",
      "train loss 5.1857\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for i in range(10):\n",
    "    train(10000, mnist.train)\n",
    "    test()\n",
    "print(\"XXXX\")\n",
    "for i in range(10):\n",
    "    train(10000, mnist.train, 1e-5)\n",
    "    test() \n",
    "print(\"XXXX\")\n",
    "for i in range(10):\n",
    "    train(10000, mnist.train, 1e-6)\n",
    "    test()\n",
    "print(\"XXXX\")\n",
    "for i in range(10):\n",
    "    train(10000, mnist.train, 1e-7)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "grad norm 18.5843177063\n",
      "loss 5.1857\n"
     ]
    }
   ],
   "source": [
    "gs_np, loss = sess.run([gs, cross_entropy], feed_dict=train_feed_dic)\n",
    "print(\"train\")\n",
    "print(\"grad norm\",influence.lnorm(gs_np))\n",
    "print(\"loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "grad norm 6245.49428715\n",
      "loss 1277.04\n"
     ]
    }
   ],
   "source": [
    "gs_np, loss = sess.run([gs, cross_entropy], feed_dict=test_feed_dic)\n",
    "print(\"test\")\n",
    "print(\"grad norm\",influence.lnorm(gs_np))\n",
    "print(\"loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cgel/deep_quad/mnist_convnet_corrupted.ckpt'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, \"/home/cgel/deep_quad/mnist_convnet_corrupted.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
