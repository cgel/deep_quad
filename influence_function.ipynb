{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import influence\n",
    "from mnist_convnet import deepnn\n",
    "from utils import corrupt_mnist\n",
    "import copy\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "# Import data\n",
    "mnist = corrupt_mnist(input_data.read_data_sets(\"mnist_data\", one_hot=True), 0.03)\n",
    "\n",
    "# Create the model\n",
    "with tf.name_scope(\"net\"):\n",
    "    input_ph = tf.placeholder(tf.float32, [None, 784])\n",
    "    y, weights = deepnn(input_ph)\n",
    "\n",
    "# Define loss and optimizer\n",
    "with tf.name_scope(\"loss\"):\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10], name=\"y_target\")\n",
    "    batch_loss = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)\n",
    "    regularization = tf.reduce_sum( [tf.nn.l2_loss(w) for w in weights])\n",
    "    cross_entropy = tf.reduce_sum(batch_loss) + regularization * 0.001\n",
    "\n",
    "lr = tf.Variable(0.1)\n",
    "opt = tf.train.AdamOptimizer(lr)\n",
    "grads_and_vars = opt.compute_gradients(cross_entropy)\n",
    "train_step = opt.apply_gradients(grads_and_vars)\n",
    "\n",
    "# Test trained model\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "gs = [g for g,v in grads_and_vars if g is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saver.restore(sess, \"/home/cgel/deep_quad/mnist_convnet_corrupted.ckpt\")\n",
    "\n",
    "summary_writter = tf.summary.FileWriter(\"./Hvp_summaries\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_feed_dic = {input_ph: mnist.test.images, y_: mnist.test.labels}\n",
    "\n",
    "batch_xs, batch_ys = mnist.train.next_batch(mnist.test.images.shape[0])\n",
    "train_feed_dic = {input_ph:batch_xs, y_:batch_ys}\n",
    "\n",
    "testset = (mnist.test.images, mnist.test.labels)\n",
    "trainset = (mnist.train.images, mnist.train.labels)\n",
    "#trainset = (mnist.train.images[0:10000], mnist.train.labels[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 0.11355\n",
      "- iter: 0\n",
      "Error: 0.162412480722\n",
      "dad: 0.000178858786579\n",
      "alpha: 72.0938086232\n",
      "beta: 2.04564644968\n",
      "Ad scaling: 0.0242070441411\n",
      "- iter: 1\n",
      "Error: 0.112668858627\n",
      "dad: 0.000848822907774\n",
      "alpha: 31.0757582494\n",
      "beta: 0.481247986026\n",
      "Ad scaling: 0.0224415272928\n",
      "- iter: 2\n",
      "Error: 0.0951080621811\n",
      "dad: 0.000281123951726\n",
      "alpha: 45.1554216454\n",
      "beta: 0.712569245963\n",
      "Ad scaling: 0.0184562325042\n",
      "- iter: 3\n",
      "Error: 0.0672559756662\n",
      "dad: 0.000220587374809\n",
      "alpha: 41.0066388405\n",
      "beta: 0.500065257628\n",
      "Ad scaling: 0.0179880184422\n",
      "- iter: 4\n",
      "Error: 0.0599372183621\n",
      "dad: 0.000113202056796\n",
      "alpha: 39.9583172315\n",
      "beta: 0.794203332819\n",
      "Ad scaling: 0.0217350714731\n",
      "- iter: 5\n",
      "Error: 0.0395181733315\n",
      "dad: 0.000155126896407\n",
      "alpha: 23.1582698209\n",
      "beta: 0.434711025004\n",
      "Ad scaling: 0.0304292269451\n",
      "- iter: 6\n",
      "Error: 0.0301927786964\n",
      "dad: 4.48930097367e-05\n",
      "alpha: 34.7868532922\n",
      "beta: 0.583730404486\n",
      "Ad scaling: 0.0240857999965\n",
      "- iter: 7\n",
      "Error: 0.017551961602\n",
      "dad: 2.88606135299e-05\n",
      "alpha: 31.5864358464\n",
      "beta: 0.337944331296\n",
      "Ad scaling: 0.0240584741422\n",
      "- iter: 8\n",
      "Error: 0.0114299700155\n",
      "dad: 5.83813929829e-06\n",
      "alpha: 52.7687608415\n",
      "beta: 0.424071472038\n",
      "Ad scaling: 0.0169362320985\n",
      "- iter: 9\n",
      "Error: 0.00808992391637\n",
      "dad: 2.37056443718e-06\n",
      "alpha: 55.1110444543\n",
      "beta: 0.500954062416\n",
      "Ad scaling: 0.0167752678701\n",
      "- iter: 10\n",
      "Error: 0.00516681932513\n",
      "dad: 1.29980695626e-06\n",
      "alpha: 50.3511567805\n",
      "beta: 0.40790483083\n",
      "Ad scaling: 0.0171881638826\n",
      "- iter: 11\n",
      "Error: 0.00387851551746\n",
      "dad: 5.03690278317e-07\n",
      "alpha: 53.0009421254\n",
      "beta: 0.563484699355\n",
      "Ad scaling: 0.0177490683607\n",
      "- iter: 12\n",
      "Error: 0.00288051428833\n",
      "dad: 3.36387724537e-07\n",
      "alpha: 44.7186976392\n",
      "beta: 0.55158524643\n",
      "Ad scaling: 0.0197182637785\n",
      "- iter: 13\n",
      "Error: 0.00200224182547\n",
      "dad: 2.18698834913e-07\n",
      "alpha: 37.9398367632\n",
      "beta: 0.483160041041\n",
      "Ad scaling: 0.0221470301528\n",
      "- iter: 14\n",
      "Error: 0.0012446519417\n",
      "dad: 8.81392937678e-08\n",
      "alpha: 45.4844943006\n",
      "beta: 0.386419620199\n",
      "Ad scaling: 0.0182367990346\n",
      "- iter: 15\n",
      "Error: 0.000807905621722\n",
      "dad: 2.39368239126e-08\n",
      "alpha: 64.7180735463\n",
      "beta: 0.421338460299\n",
      "Ad scaling: 0.0138127598513\n",
      "- iter: 16\n",
      "Error: 0.000575133351641\n",
      "dad: 1.19473039608e-08\n",
      "alpha: 54.6327795947\n",
      "beta: 0.506780970026\n",
      "Ad scaling: 0.0169873839898\n",
      "- iter: 17\n",
      "Error: 0.000470813687878\n",
      "dad: 6.96594514808e-09\n",
      "alpha: 47.4857671045\n",
      "beta: 0.670131082424\n",
      "Ad scaling: 0.0198141639285\n",
      "- iter: 18\n",
      "Error: 0.000369860994592\n",
      "dad: 9.89357346796e-09\n",
      "alpha: 22.4052651344\n",
      "beta: 0.61709348387\n",
      "Ad scaling: 0.0377185960162\n",
      "- iter: 19\n",
      "Error: 0.000228733234229\n",
      "dad: 3.37356419586e-09\n",
      "alpha: 40.5476092294\n",
      "beta: 0.382494528725\n",
      "Ad scaling: 0.0187287747747\n",
      "- iter: 20\n",
      "Error: 0.000163329389185\n",
      "dad: 1.25790577757e-09\n",
      "alpha: 41.594063132\n",
      "beta: 0.509825124758\n",
      "Ad scaling: 0.0213367332385\n",
      "- iter: 21\n",
      "Error: 0.000140830811513\n",
      "dad: 6.06685849985e-10\n",
      "alpha: 43.9680117273\n",
      "beta: 0.74370917607\n",
      "Ad scaling: 0.0213581417412\n",
      "- iter: 22\n",
      "Error: 9.02001087999e-05\n",
      "dad: 7.80337925164e-10\n",
      "alpha: 25.4226675398\n",
      "beta: 0.409979408112\n",
      "Ad scaling: 0.0297159276282\n",
      "- iter: 23\n",
      "Error: 5.55602608382e-05\n",
      "dad: 1.70181598793e-10\n",
      "alpha: 47.7917878473\n",
      "beta: 0.379687068348\n",
      "Ad scaling: 0.0173232324041\n",
      "- iter: 24\n",
      "Error: 3.61047824803e-05\n",
      "dad: 4.81316883287e-11\n",
      "alpha: 64.1594432751\n",
      "beta: 0.421960945351\n",
      "Ad scaling: 0.013992699689\n",
      "- iter: 25\n",
      "Error: 2.45700582637e-05\n",
      "dad: 2.18168070785e-11\n",
      "alpha: 59.727281475\n",
      "beta: 0.463511750733\n",
      "Ad scaling: 0.0153354273317\n",
      "- iter: 26\n",
      "Error: 1.70856481974e-05\n",
      "dad: 1.1721511401e-11\n",
      "alpha: 51.5277374898\n",
      "beta: 0.482711302817\n",
      "Ad scaling: 0.0175719099206\n",
      "- iter: 27\n",
      "Error: 1.10998525879e-05\n",
      "dad: 5.28658975999e-12\n",
      "alpha: 55.1488607822\n",
      "beta: 0.423299003853\n",
      "Ad scaling: 0.015806662285\n",
      "- iter: 28\n",
      "Error: 9.72172932414e-06\n",
      "dad: 2.74452600586e-12\n",
      "alpha: 44.9668071892\n",
      "beta: 0.764952716312\n",
      "Ad scaling: 0.022064932291\n",
      "- iter: 29\n",
      "Error: 6.05901041219e-06\n",
      "dad: 2.78631688615e-12\n",
      "alpha: 33.8815668964\n",
      "beta: 0.389010906137\n",
      "Ad scaling: 0.0225882571485\n"
     ]
    }
   ],
   "source": [
    "scale = float(len(trainset[0]))\n",
    "inf = influence.Influence(cross_entropy/scale, input_ph, y_, testset, trainset, cg_iters = 30, dampening=0.001, vervose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inf.recompute_s(cg_iters = 20, dampening=4e-2, vervose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n",
      "23500\n",
      "24000\n",
      "24500\n",
      "25000\n",
      "25500\n",
      "26000\n",
      "26500\n",
      "27000\n",
      "27500\n",
      "28000\n",
      "28500\n",
      "29000\n",
      "29500\n",
      "30000\n",
      "30500\n",
      "31000\n",
      "31500\n",
      "32000\n",
      "32500\n",
      "33000\n",
      "33500\n",
      "34000\n",
      "34500\n",
      "35000\n",
      "35500\n",
      "36000\n",
      "36500\n",
      "37000\n",
      "37500\n",
      "38000\n",
      "38500\n",
      "39000\n",
      "39500\n",
      "40000\n",
      "40500\n",
      "41000\n",
      "41500\n",
      "42000\n",
      "42500\n",
      "43000\n",
      "43500\n",
      "44000\n",
      "44500\n",
      "45000\n",
      "45500\n",
      "46000\n",
      "46500\n",
      "47000\n",
      "47500\n",
      "48000\n",
      "48500\n",
      "49000\n",
      "49500\n",
      "50000\n",
      "50500\n",
      "51000\n",
      "51500\n",
      "52000\n",
      "52500\n",
      "53000\n",
      "53500\n",
      "54000\n",
      "54500\n"
     ]
    }
   ],
   "source": [
    "trainset_inf = []\n",
    "for i in range(len(mnist.train.labels)):\n",
    "    z_inf = z = (mnist.train.images[i:i+1], mnist.train.labels[i:i+1])\n",
    "    influ, z_grad = inf.of_and_g(z)\n",
    "    trainset_inf.append( (influ, i))\n",
    "    if i % 1000==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "influences = [0]*len(mnist.train.labels)\n",
    "for i in range(len(mnist.train.labels)):\n",
    "    j = trainset_inf[i][1]\n",
    "    influences[j] = trainset_inf[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset_inf.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank = np.abs(trainset_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rank.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-5.7187035693573307e-05, 5632),\n",
       " (-5.7176692605409585e-05, 4071),\n",
       " (-5.5964669225971875e-05, 47266),\n",
       " (-5.3027766401925192e-05, 11256),\n",
       " (-4.8352770130932754e-05, 16297),\n",
       " (-4.7952599242506722e-05, 5952),\n",
       " (-4.7247628367053096e-05, 34272),\n",
       " (-4.5420109124449937e-05, 15786),\n",
       " (-4.5190334896361151e-05, 16175),\n",
       " (-4.4237209845476855e-05, 8692)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_inf[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5.1811764020470719e-05, 12254),\n",
       " (5.5368290608592829e-05, 17454),\n",
       " (5.7482173112077817e-05, 51698),\n",
       " (5.8116521792328513e-05, 9700),\n",
       " (5.859773315108896e-05, 54783),\n",
       " (6.0696809478955061e-05, 31141),\n",
       " (6.3410568113653198e-05, 37399),\n",
       " (6.384117171931436e-05, 10744),\n",
       " (6.7289159892069961e-05, 15775)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_inf[-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "influences_corrupted = []\n",
    "influences_non_corrupted = []\n",
    "grads_corrupted = []\n",
    "grads_non_corrupted = []\n",
    "#size = len(mnist.train.labels)\n",
    "size = 1000\n",
    "for i in range(size):\n",
    "    z = (mnist.train.images[i:i+1], mnist.train.labels[i:i+1])\n",
    "    influ, z_grad = inf.of_and_g(z)\n",
    "    if mnist.train.corrupted_mask[i]:\n",
    "        influences_corrupted.append(influ)\n",
    "        grads_corrupted.append(z_grad)\n",
    "    else:\n",
    "        influences_non_corrupted.append(influ)\n",
    "        grads_non_corrupted.append(z_grad)\n",
    "all_influences = influences_corrupted + influences_non_corrupted\n",
    "all_grads = grads_corrupted + grads_non_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non corrupted\n",
      "mean -6.47728385977e-08\n",
      "std 1.21111189844e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"non corrupted\")\n",
    "print(\"mean\",np.mean( influences_non_corrupted))\n",
    "print(\"std\",np.std( influences_non_corrupted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrupted\n",
      "mean -1.88751401152e-06\n",
      "std 5.31467498935e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"corrupted\")\n",
    "print(\"mean\",np.mean( influences_corrupted))\n",
    "print(\"std\",np.std( influences_corrupted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inf.s = influence.lset(inf.s, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def train(n, mnist=mnist, learning_rate=0.1e-4):\n",
    "#    sess.run(tf.assign(lr, learning_rate))\n",
    "#    for _ in range(n):\n",
    "#        batch_xs, batch_ys = mnist.train.next_batch(64)\n",
    "#        sess.run(train_step, feed_dict={input_ph: batch_xs, y_: batch_ys})\n",
    "        \n",
    "def test():\n",
    "    test_acc, test_loss = sess.run([accuracy, cross_entropy], feed_dict={input_ph: mnist.test.images,\n",
    "                                  y_: mnist.test.labels})\n",
    "    train_acc, train_loss = sess.run([accuracy, cross_entropy], feed_dict=train_feed_dic)\n",
    "    print(\"test acc\", test_acc)\n",
    "    print(\"test loss\", test_loss)\n",
    "    print(\"train acc\", train_acc)\n",
    "    print(\"train loss\", train_loss) \n",
    "    print(\"---\")\n",
    "    \n",
    "def testset_loss():\n",
    "    return sess.run(cross_entropy, feed_dict={input_ph: mnist.test.images, y_: mnist.test.labels})\n",
    "\n",
    "def train(n, trainset, learning_rate=0.1e-4):\n",
    "    sess.run(tf.assign(lr, learning_rate))\n",
    "    for _ in range(n):\n",
    "        batch_xs, batch_ys = trainset.next_batch(500)\n",
    "        sess.run(train_step, feed_dict={input_ph: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return a new dataset \n",
    "def mnist_i(i):\n",
    "    new_mnist = copy.deepcopy(mnist)\n",
    "    new_len = new_mnist.train.images.shape[0] -1\n",
    "    new_images_shape = [new_len] + list(new_mnist.train.images.shape[1:])\n",
    "    new_labels_shape = [new_len] + list(new_mnist.train.labels.shape[1:])\n",
    "    new_mnist.train.images.resize(new_images_shape)\n",
    "    new_mnist.train.labels.resize(new_labels_shape)\n",
    "    new_mnist.train.images[:] = np.delete(mnist.train.images, i, axis=0)\n",
    "    new_mnist.train.labels[:] = np.delete(mnist.train.labels, i, axis=0)\n",
    "    return new_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return a new dataset \n",
    "def mnist_i2(i):\n",
    "    return (np.delete(mnist.train.images, i, axis=0), np.delete(mnist.train.labels, i, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data):\n",
    "        self.images = data[0]\n",
    "        self.labels = data[1]\n",
    "        self.a = 0 \n",
    "        self.b = None \n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        if self.b == None or self.b == len(self.labels):\n",
    "            self.a = 0\n",
    "            self.b = batch_size\n",
    "        else:\n",
    "            self.a = self.b\n",
    "            self.b = min(self.a + batch_size, len(self.labels) )\n",
    "            \n",
    "        return (self.images[self.a:self.b], self.labels[self.a:self.b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel/__main__.py:9: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4071.0\n",
      "47266.0\n"
     ]
    }
   ],
   "source": [
    "# leave one out retraining \n",
    "subset = rank[0:5]\n",
    "influence_acc = []\n",
    "grads_l = []\n",
    "saver.restore(sess, \"/home/cgel/deep_quad/mnist_convnet_corrupted.ckpt\")\n",
    "base_testset_loss = testset_loss()\n",
    "for _,i in subset:\n",
    "    print(i)\n",
    "    z = (mnist.train.images[i:i+1], mnist.train.labels[i:i+1])\n",
    "    z_influ, z_grad = inf.of_and_g(z)\n",
    "    grads_l.append(z_grad*scale)\n",
    "    new_mnist = Dataset(mnist_i2(i))\n",
    "    train(15000, new_mnist, learning_rate=1e-7)\n",
    "    d_loss = base_testset_loss - testset_loss()\n",
    "    influence_acc.append( (z_influ * scale, d_loss) )\n",
    "    saver.restore(sess, \"/home/cgel/deep_quad/mnist_convnet_corrupted.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"influence-d_loss\", influence_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "influence d_loss\n",
      "-3.42003487964 -2.51477\n",
      "-3.42988441918 -2.51343\n",
      "-3.31553294259 -2.43469\n",
      "-3.18449001304 -2.54724\n",
      "-2.89721718932 -2.53955\n",
      "-2.80471673122 -2.55725\n",
      "-2.8584670027 -2.57825\n",
      "-2.72052093322 -2.47253\n",
      "-2.71432353466 -2.61023\n",
      "-2.66856245442 -2.5813\n",
      "-2.60808382287 -2.50586\n",
      "-2.50794371573 -2.45508\n",
      "-2.50656829854 -2.54211\n",
      "-2.39679929708 -2.54114\n",
      "-2.42648161668 -2.46692\n",
      "-2.33718128971 -2.50305\n",
      "-2.22871083264 -2.53137\n",
      "-2.13204273027 -2.54834\n",
      "-2.0511296082 -2.61658\n",
      "-2.08956744985 -2.5564\n"
     ]
    }
   ],
   "source": [
    "infs = []\n",
    "d_losses = []\n",
    "print(\"influence\", \"d_loss\")\n",
    "for pair in influence_acc:\n",
    "    infs.append(pair[0])\n",
    "    d_losses.append(pair[1])\n",
    "    print(pair[0], pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff5af4bc828>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAFkCAYAAABmeZIKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff5bc61cb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(infs, d_losses - avrg, \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff5bc5347b8>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAFkCAYAAACAUFlOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff5bc57f0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(infs, d_losses - avrg, \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.027689653809073733, -12.173828) False\n",
      "(2.253888293622941, -12.064087) False\n",
      "(-0.057892054706257245, -12.17627) True\n",
      "(-0.028630717219882418, -12.174316) False\n",
      "(-0.015116766469772114, -12.174805) False\n",
      "(0.017373136347864637, -12.154297) False\n",
      "(-0.027889592524935058, -12.174683) False\n",
      "(-0.028365732707147373, -12.173828) False\n",
      "(-0.028661911857935651, -12.174316) False\n",
      "(-0.032132640476745244, -12.174683) False\n",
      "(0.42866204244207395, -12.179932) False\n",
      "(-0.029064536376452454, -12.174072) False\n",
      "(-0.16695554828166648, -12.234497) False\n",
      "(-0.094426384465995383, -12.169678) False\n",
      "(-0.099014407147698935, -12.190796) True\n",
      "(0.053566588407716331, -12.184204) False\n",
      "(-0.053189263293645928, -12.175903) False\n",
      "(-0.028707009974843212, -12.174072) False\n",
      "(-0.02871165062694192, -12.174072) False\n",
      "(-0.029057295559478669, -12.173828) False\n",
      "(-0.028698393551712664, -12.174194) False\n",
      "(0.0093212496818373403, -12.175415) False\n",
      "(-0.031820806585119987, -12.175049) False\n",
      "(-0.031968775614441003, -12.173096) False\n",
      "(-0.13891370975072093, -12.168213) False\n",
      "(-0.0289453283844332, -12.174072) False\n",
      "(-0.028126253955734759, -12.173828) False\n",
      "(-0.028758085434260616, -12.17395) False\n",
      "(-0.028775164060898528, -12.174194) False\n",
      "(-0.028002289455125728, -12.174072) False\n",
      "(-0.028708825708656516, -12.174072) False\n",
      "(-0.034650515383163882, -12.174805) False\n",
      "(-0.35479133025095866, -12.287598) False\n",
      "(-0.028808373064501125, -12.174072) False\n",
      "(-0.028697504578234501, -12.174072) False\n",
      "(-0.028727529954794551, -12.174194) False\n",
      "(-0.028824542027475197, -12.174072) False\n",
      "(-0.036531704679168553, -12.175659) False\n",
      "(-0.035695977415595159, -12.187988) True\n",
      "(-0.035818258348613297, -12.174194) False\n",
      "(-0.39518391828252675, -12.18457) False\n",
      "(-0.029854326347444893, -12.174072) False\n",
      "(-0.077706641540831178, -12.209473) False\n",
      "(-0.028652908209206296, -12.174316) False\n",
      "(-0.02956857592495421, -12.174072) False\n",
      "(-0.028965743274697586, -12.174316) False\n",
      "(-0.034573797505071946, -12.172119) False\n",
      "(-0.029061834659685482, -12.174561) False\n",
      "(-0.028365628225029971, -12.174316) False\n",
      "(-0.025527094635741099, -12.172485) False\n",
      "(-0.024994186571189458, -12.174072) True\n",
      "(-0.028389021934152603, -12.174072) False\n",
      "(-0.028687421943229818, -12.174316) False\n",
      "(-0.030765247987854516, -12.174072) False\n",
      "(-0.028705537384252078, -12.174194) False\n",
      "(-0.10481996777167435, -12.171509) False\n",
      "(-0.031523699990862464, -12.174194) False\n",
      "(-0.022508554127498304, -12.176636) False\n",
      "(-0.03674275291951079, -12.172241) False\n",
      "(-0.1877185612464416, -12.183716) False\n",
      "(-0.036980494996716184, -12.105225) False\n",
      "(-0.029450139292092059, -12.174316) False\n",
      "(-0.076631855060252385, -12.179565) False\n",
      "(-0.029584937117285715, -12.173828) False\n",
      "(-0.028736532420442495, -12.174194) False\n",
      "(-0.028193482149302396, -12.174072) False\n",
      "(-0.031966299446420376, -12.174561) False\n",
      "(-0.027226514149741865, -12.172852) False\n",
      "(-0.028700351223237552, -12.174316) False\n",
      "(-0.10792936071174486, -12.193481) False\n",
      "(0.020699151886162392, -12.172119) False\n"
     ]
    }
   ],
   "source": [
    "influence_acc\n",
    "cu = 0\n",
    "for i in range(len(influence_acc)):\n",
    "    print(influence_acc[i], mnist.train.corrupted_mask[i])\n",
    "    cu += influence_acc[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avrg = cu/len(influence_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.37305\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, \"/home/cgel/deep_quad/mnist_convnet_corrupted.ckpt\")\n",
    "base_testset_loss = testset_loss()\n",
    "train(10000, mnist.train, learning_rate=1e-7)\n",
    "d_loss = base_testset_loss - testset_loss()\n",
    "print(d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver.restore(sess, \"/home/cgel/deep_quad/mnist_convnet_corrupted.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc 0.0846\n",
      "test loss 30870.3\n",
      "train acc 0.0891\n",
      "train loss 31078.4\n",
      "---\n",
      "test acc 0.9632\n",
      "test loss 1621.01\n",
      "train acc 0.9499\n",
      "train loss 2671.71\n",
      "---\n",
      "test acc 0.9712\n",
      "test loss 1323.3\n",
      "train acc 0.9639\n",
      "train loss 1933.37\n",
      "---\n",
      "test acc 0.9732\n",
      "test loss 1229.11\n",
      "train acc 0.9698\n",
      "train loss 1451.83\n",
      "---\n",
      "test acc 0.9725\n",
      "test loss 1166.37\n",
      "train acc 0.9756\n",
      "train loss 1049.5\n",
      "---\n",
      "test acc 0.9734\n",
      "test loss 1083.27\n",
      "train acc 0.9822\n",
      "train loss 731.857\n",
      "---\n",
      "test acc 0.9726\n",
      "test loss 1060.42\n",
      "train acc 0.9905\n",
      "train loss 486.994\n",
      "---\n",
      "test acc 0.9716\n",
      "test loss 1048.83\n",
      "train acc 0.9961\n",
      "train loss 306.672\n",
      "---\n",
      "test acc 0.9711\n",
      "test loss 1017.23\n",
      "train acc 0.9983\n",
      "train loss 184.784\n",
      "---\n",
      "test acc 0.9701\n",
      "test loss 1028.05\n",
      "train acc 0.9988\n",
      "train loss 113.906\n",
      "---\n",
      "test acc 0.9704\n",
      "test loss 1045.9\n",
      "train acc 0.9994\n",
      "train loss 69.462\n",
      "---\n",
      "XXXX\n",
      "test acc 0.9698\n",
      "test loss 1084.29\n",
      "train acc 0.9999\n",
      "train loss 42.4314\n",
      "---\n",
      "test acc 0.9689\n",
      "test loss 1126.6\n",
      "train acc 0.9999\n",
      "train loss 32.3282\n",
      "---\n",
      "test acc 0.9689\n",
      "test loss 1157.06\n",
      "train acc 1.0\n",
      "train loss 19.7326\n",
      "---\n",
      "test acc 0.9695\n",
      "test loss 1188.89\n",
      "train acc 1.0\n",
      "train loss 14.7018\n",
      "---\n",
      "test acc 0.9667\n",
      "test loss 1287.82\n",
      "train acc 0.9994\n",
      "train loss 40.3506\n",
      "---\n",
      "test acc 0.9697\n",
      "test loss 1238.43\n",
      "train acc 1.0\n",
      "train loss 10.3981\n",
      "---\n",
      "test acc 0.9693\n",
      "test loss 1251.98\n",
      "train acc 1.0\n",
      "train loss 9.45525\n",
      "---\n",
      "test acc 0.9683\n",
      "test loss 1322.95\n",
      "train acc 1.0\n",
      "train loss 10.986\n",
      "---\n",
      "test acc 0.9697\n",
      "test loss 1281.04\n",
      "train acc 1.0\n",
      "train loss 7.83585\n",
      "---\n",
      "test acc 0.9698\n",
      "test loss 1284.01\n",
      "train acc 1.0\n",
      "train loss 7.35903\n",
      "---\n",
      "test acc 0.9694\n",
      "test loss 1299.8\n",
      "train acc 1.0\n",
      "train loss 7.18464\n",
      "---\n",
      "test acc 0.9695\n",
      "test loss 1306.42\n",
      "train acc 1.0\n",
      "train loss 6.74382\n",
      "---\n",
      "test acc 0.9689\n",
      "test loss 1314.59\n",
      "train acc 1.0\n",
      "train loss 6.47041\n",
      "---\n",
      "test acc 0.9691\n",
      "test loss 1313.23\n",
      "train acc 1.0\n",
      "train loss 6.18862\n",
      "---\n",
      "test acc 0.9697\n",
      "test loss 1303.65\n",
      "train acc 1.0\n",
      "train loss 5.90618\n",
      "---\n",
      "XXXX\n",
      "test acc 0.9694\n",
      "test loss 1295.51\n",
      "train acc 1.0\n",
      "train loss 5.67874\n",
      "---\n",
      "test acc 0.9694\n",
      "test loss 1295.59\n",
      "train acc 1.0\n",
      "train loss 5.58141\n",
      "---\n",
      "test acc 0.9692\n",
      "test loss 1291.66\n",
      "train acc 1.0\n",
      "train loss 5.55953\n",
      "---\n",
      "test acc 0.9694\n",
      "test loss 1291.77\n",
      "train acc 1.0\n",
      "train loss 5.52102\n",
      "---\n",
      "test acc 0.9691\n",
      "test loss 1290.52\n",
      "train acc 1.0\n",
      "train loss 5.46961\n",
      "---\n",
      "test acc 0.9692\n",
      "test loss 1282.54\n",
      "train acc 1.0\n",
      "train loss 5.41735\n",
      "---\n",
      "test acc 0.9691\n",
      "test loss 1282.88\n",
      "train acc 1.0\n",
      "train loss 5.39521\n",
      "---\n",
      "test acc 0.9693\n",
      "test loss 1279.39\n",
      "train acc 1.0\n",
      "train loss 5.34093\n",
      "---\n",
      "test acc 0.9689\n",
      "test loss 1285.67\n",
      "train acc 1.0\n",
      "train loss 5.34137\n",
      "---\n",
      "test acc 0.9689\n",
      "test loss 1281.23\n",
      "train acc 1.0\n",
      "train loss 5.2611\n",
      "---\n",
      "XXXX\n",
      "test acc 0.9691\n",
      "test loss 1280.37\n",
      "train acc 1.0\n",
      "train loss 5.22092\n",
      "---\n",
      "test acc 0.9692\n",
      "test loss 1278.35\n",
      "train acc 1.0\n",
      "train loss 5.22632\n",
      "---\n",
      "test acc 0.9693\n",
      "test loss 1278.46\n",
      "train acc 1.0\n",
      "train loss 5.21676\n",
      "---\n",
      "test acc 0.9692\n",
      "test loss 1277.41\n",
      "train acc 1.0\n",
      "train loss 5.21618\n",
      "---\n",
      "test acc 0.9694\n",
      "test loss 1277.23\n",
      "train acc 1.0\n",
      "train loss 5.21483\n",
      "---\n",
      "test acc 0.9693\n",
      "test loss 1278.12\n",
      "train acc 1.0\n",
      "train loss 5.20718\n",
      "---\n",
      "test acc 0.9693\n",
      "test loss 1277.95\n",
      "train acc 1.0\n",
      "train loss 5.19952\n",
      "---\n",
      "test acc 0.9693\n",
      "test loss 1277.82\n",
      "train acc 1.0\n",
      "train loss 5.20765\n",
      "---\n",
      "test acc 0.9692\n",
      "test loss 1277.34\n",
      "train acc 1.0\n",
      "train loss 5.19207\n",
      "---\n",
      "test acc 0.9695\n",
      "test loss 1277.04\n",
      "train acc 1.0\n",
      "train loss 5.1857\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for i in range(10):\n",
    "    train(10000, mnist.train)\n",
    "    test()\n",
    "print(\"XXXX\")\n",
    "for i in range(10):\n",
    "    train(10000, mnist.train, 1e-5)\n",
    "    test() \n",
    "print(\"XXXX\")\n",
    "for i in range(10):\n",
    "    train(10000, mnist.train, 1e-6)\n",
    "    test()\n",
    "print(\"XXXX\")\n",
    "for i in range(10):\n",
    "    train(10000, mnist.train, 1e-7)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "grad norm 18.5843177063\n",
      "loss 5.1857\n"
     ]
    }
   ],
   "source": [
    "gs_np, loss = sess.run([gs, cross_entropy], feed_dict=train_feed_dic)\n",
    "print(\"train\")\n",
    "print(\"grad norm\",influence.lnorm(gs_np))\n",
    "print(\"loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "grad norm 6245.49428715\n",
      "loss 1277.04\n"
     ]
    }
   ],
   "source": [
    "gs_np, loss = sess.run([gs, cross_entropy], feed_dict=test_feed_dic)\n",
    "print(\"test\")\n",
    "print(\"grad norm\",influence.lnorm(gs_np))\n",
    "print(\"loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cgel/deep_quad/mnist_convnet_corrupted.ckpt'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, \"/home/cgel/deep_quad/mnist_convnet_corrupted.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
